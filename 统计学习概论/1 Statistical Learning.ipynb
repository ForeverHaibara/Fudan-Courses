{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 统计学习概论\n",
    "\n",
    "统计学习 (statistical learning) 是基于数据构建概率统计模型并运用模型对数据进行预测及分析的一门学科。\n",
    "\n",
    "统计学习的方法包括: 有监督学习 (supervised learning), 无监督学习 (unsupervised learning), 强化学习 (reinforcement learning) 等.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 监督学习与无监督学习\n",
    "\n",
    "### 监督学习\n",
    "\n",
    "监督学习已知很多数据的输入输出 $(X,Y)$. \n",
    "对于每条输入数据 $X$ 可以看成一个列向量. 每条输出数据 $Y$ 也可以看成一个列向量. 一组数据 (输入与输出) $(X,Y)$ 相当于从一个联合概率分布中产生.\n",
    "\n",
    "监督学习的模型可以是概率模型, 如预测 $P(Y|X)$, 或非概率模型, 如决策函数 (decision function) $Y = f(X)$.\n",
    "\n",
    "### 无监督学习\n",
    "\n",
    "无监督学习不知道输出数据, 只知道输入数据 $X$. 无监督学习试图发掘数据中的统计规律与潜在结构, 如降维和聚类."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概念\n",
    "\n",
    "### 模型\n",
    "\n",
    "假设模型是一个函数 $f$, 属于一定的函数空间 $\\mathcal F$. 对于参数化模型 (parametric model), $\\mathcal F$ 是不同参数时函数的集合 $\\mathcal F = \\{f:\\ f_\\theta, \\theta\\in \\Omega\\}$.\n",
    "\n",
    "### 损失函数和风险函数\n",
    "\n",
    "损失函数 (loss function) 度量一次预测的好坏. 风险函数是多次损失函数的平均值. 常见的损失函数有:\n",
    "\n",
    "* 01损失函数, $L(Y,f(X)) = \\delta_{f(X),Y}\\in\\{0,1\\}$.\n",
    "* 平方损失函数, $L(Y,f(X))=|Y - f(X)|^2$.\n",
    "* 绝对损失函数, $L(Y,f(X)) = |Y - f(X)|$. \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 泛化误差上界\n",
    "\n",
    "对于二分类问题 $Y\\in\\{-1,1\\}$, 使用 01损失函数, $f$ 的期望损失为 $R(f) = \\mathbb E(L(Y,f(X)))$, 用 $N$ 个数据得到的经验损失是 $\\hat R(f) = \\frac 1N\\sum_{i=1}^N L(Y_i,f(X_i))$. 假设现在有 $d$ 个模型 $f_1,\\dotsc,f_d$,\n",
    "\n",
    "**定理** \n",
    "\n",
    "$$\\mathbb P\\left(\\bigcap_{i=1}^d \\{R(f) - \\hat R(f)\\leqslant \\sqrt{\\frac{1}{2N}(\\log d - \\log \\delta)}\\}\\right)\\geqslant 1 - \\delta.$$\n",
    "\n",
    "定理表明了所有 $R(f)$ 有一定概率与估计值相差不太大.\n",
    "\n",
    "**证明**\n",
    "\n",
    "由于 $(\\sup - \\inf)\\left\\{\\mathbb E(L(Y,f(X)))-L(Y_i,f(X_i))\\right\\}\\leqslant 1$, 且 $\\mathbb E\\left(\\mathbb E(L(Y,f(X)))-L(Y_i,f(X_i))\\right) = 0$, 可用 Hoeffding 不等式推出\n",
    "$$\\mathbb P\\left(\\sum \\left(\\mathbb E(L(Y,f(X)))-L(Y_i,f(X_i))\\right)\\geqslant N\\epsilon \\right)\n",
    "\\leqslant e^{-sN\\epsilon +\\frac N8s^2}.$$\n",
    "\n",
    "令 $\\epsilon =  \\sqrt{\\frac{1}{2N}(\\log d - \\log \\delta)}$ 及 $s=4{\\epsilon}$ 得\n",
    "\n",
    "$$\\mathbb P \\left(R(f) - \\hat R(f)\\geqslant \\epsilon \\right)\\leqslant e^{-2N\\epsilon^2}=\\frac {\\delta}{d}.$$\n",
    "\n",
    "进而\n",
    "\n",
    "$$\\mathbb P\\left(\\bigcup_{i=1}^d \\{R(f) - \\hat R(f)\\geqslant \\epsilon  \\}\\right)\\leqslant  d\\cdot \\frac{\\delta}{d} = \\delta.$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1120dc956da57eca5c948a0118f4cdcd4d1b3be98c72752ed298d16085a61d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
