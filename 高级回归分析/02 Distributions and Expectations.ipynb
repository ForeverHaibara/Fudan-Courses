{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Distributions and Expectations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation of Distribution\n",
    "\n",
    "Let $X\\in\\mathbb R^k$ be a random vector with a Lebesgue p.d.f. $f_X$ and let $Y=g(X)$ where $g$ is a Borel function from $(\\mathbb R^k,\\mathcal B^k)$ to $(\\mathbb R^k, \\mathcal B^k)$. Also, $g$ has, on Lebesgue measure, almost everywhere nonvanishing Jacobian. Then $Y$ has the following Lebesgue p.d.f.\n",
    "$$f_Y(x) = \\left|{\\rm det}\\frac{\\partial g^{-1}(x)}{\\partial x}\\right|f_X(g^{-1}(x)).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Distribution \n",
    "\n",
    "Let $X_1\\sim \\chi_{n_1}^2$ and $X_2\\sim \\chi_{n_2}^2$ be independent, then we say the following has F-distribution. \n",
    "$$F = \\frac{X_1/n_1}{X_2/n_2} \\sim F(n_1,n_2)$$\n",
    "\n",
    "### T-Distribution\n",
    "\n",
    "Let $X_1\\sim N(0,1)$ and $X_2\\sim \\chi_n^2$ be independent, then we say the following has T-distribution. \n",
    "$$T = \\frac{X_1}{\\sqrt{X_2/n}}\\sim T(n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indepedence\n",
    "\n",
    "Let $(\\Omega,\\mathcal F,\\mathbb P)$ be probability measure. Let sets $A_1,\\dotsc,A_n\\in\\mathcal F$. Then $A_1,\\dotsc,A_n$ are independent if for every $I\\subset \\{1,\\dotsc,n\\}$ we have \n",
    "$$\\mathbb P(\\cap_I A_i) = \\prod_{i\\in I}\\mathbb P(A_i).$$\n",
    "\n",
    "Let $X_1,\\dotsc,X_n$ be random variables (Borel functions) on $(\\Omega,\\mathcal F,\\mathbb P)$. They are independent if and only if for any $B\\in\\mathcal B$ we have \n",
    "$$\\mathbb P(\\cap_{i=1}^n X_i^{-1}(B))=\\prod_{i=1}^n \\mathbb P(X_i^{-1}(B)).$$\n",
    "\n",
    "**Theorem** Let $X_{i,j}\\ (1\\leqslant i\\leqslant n,\\ 1\\leqslant j\\leqslant m_i)$ be independent and $f_i$ be measurable, then $f_i(X_{i,1},\\dotsc,X_{i,m_i})\\ (i=1,2,\\dotsc,n)$ is independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment\n",
    "\n",
    "Let $X$ be a random variable (Borel function), if $\\mathbb E(X^k)$ is integrable (finite) for an integer $k$, then we call it the $k$ th moment of $X$. \n",
    "\n",
    "Similarly we can define $\\mathbb E(|X|^k)$, the absolute moment, if finite. And $\\mathbb E((X - \\mathbb E(X))^k)$ is the central moment if finite.\n",
    "\n",
    "### Variance\n",
    "\n",
    "The second central moment is called the variance. For random variables $X_1,\\dotsc,X_n$, we can define the covariance matrix by \n",
    "$${\\rm Cov}(X)= \\mathbb E((X - \\mathbb E(X))(X - \\mathbb E(X))^T)$$\n",
    "where $X$ stands for the vector $X = [X_1,\\dotsc,X_n]^T$. The covariance matrix is positive semidefinite. Also, we have \n",
    "${\\rm Var}(X_1){\\rm Var}(X_2)\\geqslant {\\rm Cov}^2(X_1,X_2)$.\n",
    "\n",
    "### Correlation Coefficient \n",
    "\n",
    "The correlation coefficient of two random variables $X,Y$ is defined by \n",
    "$$\\rho (X,Y) = \\frac{\\rm Cov(X,Y)}{\\sqrt{{\\rm Var}(X){\\rm Var}(Y)}}\\in [-1,1].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inequalities\n",
    "\n",
    "### Holder's Inequality\n",
    "\n",
    "For any random variables $X,Y$ such that $\\mathbb E(X),\\mathbb E(Y),\\mathbb E(XY)$ is finite. Then, for positive numbers $p,q$ such that $1/p+1/q = 1$,\n",
    "$$\\mathbb E(|XY|)\\leqslant (\\mathbb E(|X|^p))^{\\frac 1p}(\\mathbb E(|Y|^q))^{\\frac 1q}.$$\n",
    "\n",
    "Proof: If $\\mathbb E(|X|^p)=0$ or $\\mathbb E(|Y|^q)=0$, it implies $X=0$ almost everywhere or $Y=0$ almost everywhere and the result holds. Otherwise, we may assume $\\mathbb E(|X|^p)=1=\\mathbb E(|Y|^q)$ by scaling. Note that it is easy to verify the constant version of Holder's inequality:\n",
    "$$xy\\leqslant \\frac{x^p}{p}+\\frac{y^q}{q}\\quad (x,y\\geqslant 0).$$\n",
    "\n",
    "Take the expectance in both sides and we yield the result since $1/p+1/q = 1$.\n",
    "\n",
    "### Cauchy's Inequality \n",
    "$$\\mathbb E^2(|XY|)\\leqslant \\mathbb E(|X|^2)\\mathbb E(|Y|^2)$$\n",
    "\n",
    "Proof: A direct corollary of Holder's inequality when $p=q=2$.\n",
    "\n",
    "### Lyapunov's Inequality\n",
    "\n",
    "$$\\mathbb E(|X|^r)^\\frac 1r\\leqslant \\mathbb E(|X|^s)^\\frac 1s\\quad (1\\leqslant r\\leqslant s)$$\n",
    "\n",
    "[Proof](https://math.stackexchange.com/questions/2511778/): In the Holder's inequality we take $X=|Z|^s$ and $Y\\equiv 1$ to obtain \n",
    "$$\\mathbb E(|Z|^s)\\leqslant \\mathbb E(|Z|^{sp})^{\\frac1p}.$$\n",
    "It remains to take $p = t/s$.\n",
    "\n",
    "### Minkowski's Inequality\n",
    "\n",
    "\n",
    "$$\\mathbb E(|X+Y|^p)^\\frac 1p\\leqslant \\mathbb E(|X|^p)^\\frac 1p + \\mathbb E(|Y|^p)^\\frac 1p\\quad (1\\leqslant p)$$\n",
    "\n",
    "Proof: Let $q = p/(p-1)$ such that $1/p+1/q = 1$, then \n",
    "$$\\mathbb E(|X+Y|^p)\\leqslant \\mathbb E(|X+Y|^{p-1}|X|)+\\mathbb E(|X+Y|^{p-1}|Y|)\n",
    "\\leqslant \\mathbb E(|X+Y|^{q(p-1)})^{\\frac 1q}\\mathbb E(|X|^p)^{\\frac 1p}+\\mathbb E(|X+Y|^{q(p-1)})^{\\frac 1q}\\mathbb E(|Y|^p)^{\\frac 1p}.$$\n",
    "Sort the inequality yields our desired result.\n",
    "\n",
    "### Jensen's Inequality\n",
    "\n",
    "If $f$ is convex, then\n",
    "$$f(\\mathbb E(X))\\leqslant \\mathbb E(f(X))$$\n",
    "\n",
    "Proof: Recall the property of convex functions that for any $y$ there exists $a$ such that $f(x)\\geqslant f(y)+a(x-y)$. Now let $x=X$ and $y=\\mathbb E(X)$ and taking the expectance on both sides leads to the result.\n",
    "\n",
    "### Chebyshev's Inequality\n",
    "\n",
    "Let $X$ be a random variable and $\\phi$ be a nonnegative and nondecreasing function on $[0,\\infty)$  with $\\phi(t) = \\phi(-t)$. hen we have \n",
    "$$\\phi(t)\\mathbb P\\left(|X|\\geqslant t\\right)\\ \\leqslant \\int_{|X|\\geqslant t}\\phi(X)d\\mathbb P  \\ \\leqslant \\mathbb E_\\phi (X).$$\n",
    "\n",
    "\n",
    "### Markov's Inequality\n",
    "\n",
    "If $X$ be a random variable and $\\phi$ be a nonnegative and nondecreasing function on $[0,\\infty)$ with $\\phi(t) =\\phi(-t)$, then\n",
    "\n",
    "$$\\mathbb P(|X|\\geqslant t)\\ \\leqslant \\frac{\\mathbb E(|X|)^p}{|t|^p}\\quad (p>1).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment Generating Function and Characteristic Function\n",
    "\n",
    "The moment generating function (m.g.f.) of random variable $X$ or $\\mathbb P_X$ is defined as \n",
    "$$\\psi_X(t) = \\mathbb E(e^{t^TX})$$\n",
    "\n",
    "and the characteristics function (ch.f.) is defined as \n",
    "$$\\phi_X(t)  = \\psi_{X}(it)=\\mathbb E(e^{it^TX}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1120dc956da57eca5c948a0118f4cdcd4d1b3be98c72752ed298d16085a61d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
