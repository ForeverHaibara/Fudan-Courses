{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Asymptotic Theory\n",
    "\n",
    "## Convergence\n",
    "\n",
    "Let $X,X_1,X_2,\\dotsc$ be a sequence of random vectors (vector of Borel functions) defined on a probability space $(\\Omega,\\mathcal F,\\mathbb P)$. \n",
    "\n",
    "* If for almost every (in the sense of $\\mathbb P$) $x\\in \\Omega$, we have $\\lim_n X_n(x) = X(x)$, then we say $X_n$ converges to $X$ almost surely, and write\n",
    "$$X_n\\rightarrow_{a.s.}X$$\n",
    "\n",
    "* If for any $\\epsilon>0$, $\\lim_n \\mathbb P(x:\\Vert X_n(x) - X(x)\\Vert> \\epsilon)=0$, we say $X_n$ converges to $X$ in probability, and write\n",
    "$$X_n\\rightarrow_{\\mathbb P}X$$\n",
    "\n",
    "* For $r>0$, if $\\lim_n \\mathbb E(\\Vert X_n - X\\Vert_r^r)=0$, we say $X_n$ converges to $X$ in $L_r$ or in $r$-th moment, and write\n",
    "$$X_n\\rightarrow_{L_r}X$$\n",
    "\n",
    "* Let $F,F_1,F_2,\\dotsc$ be the c.d.f of $X,X_1,X_2,\\dotsc$ (i.e. $F(x_0) = \\mathbb P(X(x)\\leqslant x_0)$). If for any continous point $x$ of $F$, $\\lim_n F_n(x) = F(x)$, then we say $X_n$ converges to $X$ in distribution and $F_n$ converges to $F$ in distribution (or weakly), and write\n",
    "$$X_n\\rightarrow_d X\\quad\\quad F_n\\rightarrow_d F$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relations\n",
    "\n",
    "* If $X_n\\rightarrow_{a.s.}X$, then $X_n\\rightarrow_{\\mathbb P}X$.\n",
    "  \n",
    "* If $X_n\\rightarrow_{L_r}X\\ (r>0)$, then $X_n\\rightarrow_{\\mathbb P} X$.\n",
    "\n",
    "* If $X_n\\rightarrow_{\\mathbb P} X$, then $X_n\\rightarrow_d X$.\n",
    "\n",
    "* If for every $\\epsilon>0$ we have $\\sum_{n=1}^{\\infty}\\mathbb P(\\Vert X_n - X\\Vert > \\epsilon)<\\infty$, then $X_n\\rightarrow_{a.s.}X$.\n",
    "\n",
    "* If $X_n\\rightarrow_d X$ and $\\mathbb P(X = c) = 1$ where $c$ is constant, then $X_n\\rightarrow_{\\mathbb P}c$.\n",
    "\n",
    "* (Skorohod) If $X_n\\rightarrow_d X$, then there exists $Y,Y_1,\\dotsc$ such that $\\mathbb P(Y_n)=\\mathbb P(X_n),\\ \\mathbb P(Y)=\\mathbb P(X)$ and $Y_n\\rightarrow_{a.s.}Y$.\n",
    "\n",
    "* If $X_n\\rightarrow_{\\mathbb P}X$, then there exists some subsequence $X_{n_j}\\rightarrow_{a.s.}X$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristic Function\n",
    "\n",
    "\n",
    "### Lévy-Cramér Continuity Theorem\n",
    "\n",
    "This theorem implies that we can prove a pointwise convergence in characteristic function to show convergence in distribution.\n",
    "\n",
    "**Theorem** Let $\\phi$ be the characteristic function of $X$. Then $X_n\\rightarrow_d X$ if and only if $\\lim_{n\\rightarrow \\infty}\\phi_{X_n}(t) = \\phi_X(t)$ for all $t\\in\\mathbb R$. [[Ref](https://arxiv.org/abs/2111.01603)]\n",
    "\n",
    "### Cramér-Wold Device\n",
    "\n",
    "**Theorem** Let $X,X_1,\\dotsc$ be random $k$-vectors. Then $X_n\\rightarrow_d X$ if and only if $c^TX_n\\rightarrow_d c^TX$ for all $c\\in\\mathbb R^k$.\n",
    "\n",
    "\n",
    "### Example of Central Limit Theorem\n",
    "\n",
    "Let $X_1,X_2,\\dotsc$ be random variables, $\\mathbb EX_1 = 0$ and ${\\rm Var}X_1=\\sigma^2<\\infty$. Then $\\frac{1}{\\sqrt n}\\sum _{i=1}^n X_i\\rightarrow_d N(0,\\sigma^2)$. \n",
    "\n",
    "**Proof** Let $\\phi_n$ be the characteristic function of $\\frac{1}{\\sqrt n}\\sum_{i=1}^n X_i$. It suffices to compute $\\lim \\phi_n(t)$ for all $t\\in\\mathbb R$. Actually we have \n",
    "\n",
    "$$\\lim_{n\\rightarrow\\infty}\\phi_n(t) = \\lim_{n\\rightarrow\\infty}\\mathbb E\\exp\\left\\{\\frac{t}{\\sqrt n}\\sum_{i=1}^n X_i\\right\\}=\\lim_{n\\rightarrow\\infty}\\left[\\mathbb Ee^{\\frac{t}{\\sqrt n}X_1}\\right]^{n}.$$\n",
    "\n",
    "Note that by Taylor's theorem for any fixed $t$ we have \n",
    "\n",
    "$$\\mathbb Ee^{\\frac{t}{\\sqrt n}X_1} =\\phi \\left(\\frac{t}{\\sqrt n}\\right) =  1-\\frac{\\sigma^2}{2n}t^2+o\\left(\\frac{1}{n}\\right)\\quad (n\\rightarrow \\infty).$$\n",
    "\n",
    "Hence \n",
    "\n",
    "$$\\lim_{n\\rightarrow\\infty}\\left[\\mathbb Ee^{\\frac{t}{\\sqrt n}X_1}\\right]^{n}\n",
    "= \\exp \\lim_{n\\rightarrow\\infty} n \\ln \\left[ 1-\\frac{\\sigma^2}{2n}t^2+o\\left(\\frac{1}{n}\\right)\\right]=\\exp\\left\\{-\\frac{\\sigma^2 t^2}{2}\\right\\}.$$\n",
    "\n",
    "The limiting function is exactly the characteristic function of $N(0,\\sigma^2)$, so we conclude the convergence in distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slutsky's Theorem\n",
    "\n",
    "**Theorem** If $X_n\\rightarrow_d X$ and $Y_n\\rightarrow c$ where $c$ is a constant, then:\n",
    "\n",
    "* $X_n+Y_n\\rightarrow_d X+c$.\n",
    "* $Y_nX_n\\rightarrow_d cX$.\n",
    "* $X_n/Y_n\\rightarrow_d X/c\\ $ if $c\\neq 0$.\n",
    "\n",
    "\n",
    "### Slutsky's Theorem of Transformations\n",
    "\n",
    "**Theorem** [[Slutsky](https://pages.stat.wisc.edu/~doksum/STAT709/n709-14.pdf)]  Let $X,X_1,\\dotsc$ and $Y$ be random $k$-vectors such that $a_n(X_n-c)\\rightarrow_d Y$ where $c\\in\\mathbb R^k$ is constant and $\\left\\{a_n\\right\\}$ is positive real numbers and $\\lim a_n=+\\infty$. Let $g:\\ \\mathbb R^k\\rightarrow \\mathbb R$ be a function.\n",
    "\n",
    "If $g$ is differentiable at $c$, then \n",
    "\n",
    "$$a_n\\left[g(X_n)-g(c)\\right]\\rightarrow_d \\nabla g(c)^TY.$$\n",
    "\n",
    "Suppose $g$ has continuous derivative of order $m>1$ in a neighborhood of $c$ and the first $m-1$ derivatives of $g$ all vanish at $c$ but the $m$-th order does not, then\n",
    "\n",
    "$$a_n^m\\left[g(X_n) - g(c)\\right]\\rightarrow_d \\frac{1}{m!}\n",
    "\\sum_{i_1=1}^k\\dotsm\\sum_{i_m=1}^k\\left.\\frac{\\partial ^mg}{\\partial x_{i_1}\\dotsm \\partial x_{i_m}}\\right|_{x=c}Y_{i_1}\\dotsm Y_{i_m}.$$\n",
    "\n",
    "Here $Y_j$ stands for the $j$-th entry.\n",
    "\n",
    "\n",
    "### Transformation on Asymptotical Normality\n",
    "\n",
    "Assume $a_n(X_n - c) \\rightarrow_d N_k(0,\\Sigma)$ is asymptotically normal with $a_n>0$ and $a_n\\rightarrow+\\infty$, then if $g$ is differentiable at $c$, we have $a_n\\left[g(X_n)-g(c)\\right]\\rightarrow_d N(0,\\nabla g(c)^T\\Sigma\\nabla g(c))$.\n",
    "\n",
    "**Proof** Let $Y = N_k(0,\\Sigma)$ so that $a_n(X_n- c)\\rightarrow_d Y$. Then $a_n\\left[g(X_n)-g(c)\\right]\\rightarrow_d \\nabla g(c)^TY$, which is a linear transformation of Gaussian distribution. Thus it is still Gaussian, $N_k(0,\\nabla g(c)^T\\Sigma\\nabla g(c))$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Law of Large Numbers\n",
    "\n",
    "\n",
    "### Weak Law of Large Numbers\n",
    "\n",
    "**Theorem** ([Feller WLLN](https://link.springer.com/article/10.1007/s12044-022-00705-3)) Let $X_1,X_2,\\dotsc$ be i.i.d., then there exists a sequence of $\\left\\{a_n\\right\\}$ such that $\\frac 1n \\sum_{i=1}^n X_i -a_n\\rightarrow_\\mathbb P 0$ if and only if $n \\mathbb P(|X_1|>n)\\rightarrow 0$.\n",
    "\n",
    "\n",
    "### Strong Law of Large Numbers\n",
    "\n",
    "**Theorem** (Kolmogorov SLLN) Let $X_1,X_2,\\dotsc$ be i.i.d., then there exists constant $c$ such that $\\frac 1n \\sum_{i=1}^n X_i\\rightarrow_{a.s.} c$ if and only if $\\mathbb E|X_1|<\\infty$. And in this case, $c = \\mathbb EX_1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "### Linderberg-Feller Central Limit Theorem\n",
    "\n",
    "**Theorem** (Linderberg-Feller) Let $X_{nj}\\ (n=1,2,\\dotsc;\\ j=1,2,\\dots,k_n)$ be independent random variables. Let $0<B_n =\\sqrt{ \\sum_{j=1}^n {\\rm Var}X_{nj}}<\\infty$ for all $n$. Then the following two \n",
    "\n",
    "$$\\lim_{n\\rightarrow\\infty}\\frac{\\max_{1\\leqslant j\\leqslant k_n}{\\rm Var}X_{nj}}{B_n^2}=0\n",
    "{\\quad{\\rm and}\\quad }\\frac{1}{B_n}\\sum_{j=1}^{k_n}\\left(X_{nj}- \\mathbb EX_{nj}\\right)\\rightarrow_d N(0,1)$$\n",
    "\n",
    "hold if and only if the following Linderberg condition holds for all $\\epsilon>0$:\n",
    "\n",
    "$$\\lim_{n\\rightarrow\\infty}\\frac{1}{B_n^2}\\sum_{j=1}^{k_n}\\mathbb E\\left\\{\n",
    "(X_{nj} - \\mathbb EX_{nj})^2\\mathbb I_{|X_{nj} - \\mathbb E {X_{nj}}|>\\epsilon}\\right\\}=0.$$\n",
    "\n",
    "### Lyaponouv Condition\n",
    "\n",
    "\n",
    "**Theorem** When there exists $\\delta>0$ satisfying the following Lyaponouv condition, \n",
    "\n",
    "$$\\lim_{n\\rightarrow \\infty}\\frac{1}{B_n^{2+\\delta}}\\sum_{j=1}^{k_n}\\mathbb E|X_{nj} - \\mathbb EX_{nj}|^{2+\\delta} = 0,\n",
    "$$\n",
    "\n",
    "then it satisfies the Linderberg condition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] https://pages.stat.wisc.edu/~doksum/STAT709/n709-14.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1120dc956da57eca5c948a0118f4cdcd4d1b3be98c72752ed298d16085a61d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
