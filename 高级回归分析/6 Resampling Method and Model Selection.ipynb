{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Resampling Method and Model Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jackknife and Bookstrip\n",
    "\n",
    "If we have an estimator $T$ for some model parameter and now we want to estimate the standard deviation / variance of $T$. Then we can apply the method of Jackknife or Bookstrip.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Selection\n",
    "\n",
    "### Forward / Backward Selection\n",
    "\n",
    "### Hybrid Approach \n",
    "\n",
    "Combine forward and backward selection in the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Optimal Model\n",
    "\n",
    "Given fixed covariates $x_1,\\dotsc,x_n\\in\\mathbb R^{ k}$, suppose now $y_1,\\dotsc,y_n\\in\\mathbb R$ is the response and $y\\sim N(\\mu,\\sigma^2I)$. We can estimate $\\hat\\mu\\in\\mathbb R^n$ by the observations $y$, e.g. $\\hat\\mu = r(y)$.\n",
    "\n",
    "Now we want to re-predict the valus of $y$, $\\hat y$, based on $\\hat\\mu$.\n",
    "\n",
    "### Generalization Gap\n",
    "\n",
    "Let \n",
    "\n",
    "Covariance penalty estimates of predicition error task\n",
    "\n",
    "$$\\mathbb E({\\rm Err}_i)= \\mathbb E({\\rm err}_i) + 2{\\rm Cov}(\\hat\\mu_i, y_i)$$\n",
    "\n",
    "\n",
    "### Degree of Freedom \n",
    "\n",
    "Use more generalized method to define the degree of freedom.\n",
    "\n",
    "$${\\rm df} = \\sigma^{-2}\\sum_{i=1}^N \\widehat{\\rm cov}(\\hat\\mu_i,y_i)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1120dc956da57eca5c948a0118f4cdcd4d1b3be98c72752ed298d16085a61d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
