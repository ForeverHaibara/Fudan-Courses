{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Approximation by Series\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Continuous function can often be approximated by series, e.g. Taylor series, Fourier series.\n",
    "\n",
    "We can model the data with series expansions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncation \n",
    "\n",
    "To do series regression, we actually use truncation. That is, we perform $(K-1)$-degree polynomial regression (which has $K$-dimensonal coefficients). When $K\\rightarrow \\infty$ is large enough, we wish that our truncated polynomial regression acts like series expansion.\n",
    "\n",
    "Assume the true model is $y = m(x)+\\epsilon$ and $x,y\\in\\mathbb R$ while $\\epsilon$ is a random noise. We are eager to find a polynomial\n",
    "$$\\hat m_K(x) = b_0 +b_1 x+\\dotsc+b_{K-1}x^{K-1}=\\beta_K^Tz_K(x)$$\n",
    "so that $\\hat m_K(x)\\approx m(x)$. Here $z_K(x) = [1,x,\\dotsc,x^{K-1}]^T$ and $\\beta_K = [b_0,\\dotsc,b_{K-1}]^T$.\n",
    "\n",
    "\n",
    "### Uniform Approximation\n",
    "\n",
    "Stone-Weierstrass states that, any continuous function on compact sets can be arbitrarily uniformly approximated by polynomials. Hence using truncation is reasonable.\n",
    "\n",
    "### Best Uniform Approximation\n",
    "\n",
    "Assume temporarily that we know $m(x)$. To define the best estimator $\\hat m_K(x)\\approx m(x)$, or to find $\\beta_K = [b_0,\\dotsc,b_{K-1}]^T$ in equivalence, we use the optimal $\\beta_K^*$ defined by the best uniform estimator:\n",
    "$$\\beta_K^*={\\rm argmin}_{\\beta_K}\\sup|\\beta_K^Tz_K(x) -m(x)|.$$\n",
    "\n",
    "Also, we denote\n",
    "$$r_K^*(x) = m(x) - \\beta_K^Tz_K(x).$$\n",
    "\n",
    "We would like to study whether the error $r_K^*(x)$ converges to zero as $K\\rightarrow\\infty$, and also its convergence rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Estimation\n",
    "\n",
    "However, in practice we do not know $m(x)$ in advance. We have only got some observations $(x_i,y_i) \\in\\mathbb R\\times \\mathbb R$ from the model $y = m(x)+\\epsilon$. Then we do not use best uniform approximation, but the polynomial regression as mentioned earlier. \n",
    "\n",
    "Denote $z_{Ki} = z_K(x_i) = [1,x_i,\\dotsc,x_i^{K-1}]^T$ and $Z_K = [z_{K1},\\dotsc,z_{Kn}]^T\\in\\mathbb R^{n\\times K}$, then the polynomial regression gives\n",
    "$$\\hat\\beta_K = (Z_K^TZ_K)^{-1}Z_K^Ty\\quad\\quad \\hat m_K(x) = \\hat\\beta_K^Tz_K(x).$$\n",
    "\n",
    "\n",
    "\n",
    "### Population Estimation\n",
    "\n",
    "We slightly modify our empirical estimator. Let $\\mathbb E(z_{Ki}z_{Ki}^T) = \\dfrac 1n \\sum_{i=1}^n z_{Ki}z_{Ki}^T$ and $\\mathbb E(z_{Ki}^Ty_i)= \\dfrac 1n \\sum_{i=1}^n z_{Ki}^Ty_i$, we define the population estimator to be\n",
    "$$\\hat\\beta_K = [\\mathbb E(z_{Ki}z_{Ki}^T)]^{-1}\\mathbb E(z_{Ki}^Ty_i).$$\n",
    "\n",
    "**WE WILL USE POPULATION ESTIMATION IN THE FOLLOWING CONTEXT.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence\n",
    "\n",
    "<font color=red>We will use population estimation in the following context.</font>\n",
    "\n",
    "\n",
    "### Design Matrix\n",
    "\n",
    "\n",
    "For simplicity we denote $Q_K = \\mathbb E(z_{Ki}z_{Ki}^T) = \\dfrac 1n \\sum_{i=1}^n z_{Ki}z_{Ki}^T$ to be the design matrix. Let $\\mathcal X$ be the domain of $x$. Define \n",
    "$$\\zeta_K =\\sup_{x\\in \\mathcal X}\\sqrt{z_K(x)^TQ_K^{-1}z_K(x)}.$$\n",
    "\n",
    "**Example**\n",
    "\n",
    "\n",
    "### Convergence\n",
    "\n",
    "**Theorem** If the following four conditions hold:\n",
    "1. $\\sup_x |m(x) - \\hat m(x)|<O(K^{-\\alpha})$ is the property of uniform approximation.\n",
    "2. $\\mathbb E(e_i^2|x_i)\\leqslant \\bar \\sigma^2<\\infty$ requires the noise has bounded variance.\n",
    "3. $Q_k\\succ 0$ is strictly positive definite.\n",
    "4. As $K$ increases as a function with respect to data number $n$, we demand $K=o(n)$ and $\\zeta_K K=o(n)$.\n",
    "\n",
    "Then $\\sup_x |r_K(x)|\\leqslant O(\\zeta_K K^{-\\alpha})$. Thus, when $\\zeta_K K^{-\\alpha}=o(1)$, our series approximation converges correctly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Convergence\n",
    "\n",
    "$$\\int (\\hat m_K(x) - m(x))^2f_X(x)x = O_p(K/n) + O_p(K^{-2\\alpha})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Whitney K.Newey. [Convergence rates and asymptotic normality for series estimators](https://www.sciencedirect.com/science/article/pii/S0304407697000110?via%3Dihub). 1997."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1120dc956da57eca5c948a0118f4cdcd4d1b3be98c72752ed298d16085a61d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
