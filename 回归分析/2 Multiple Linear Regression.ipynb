{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Multiple Linear Regression\n",
    "\n",
    "Now we have multiple factors, and the linear regression has the form ($y_i,x_{ij}\\in\\mathbb R$)\n",
    "$$y_i = \\beta_0+\\beta_1x_{i1}+\\dotsc +\\beta_k x_{ik}+\\epsilon_i,$$\n",
    "or in the matrix form, (with $x_i = [1,x_{i1},\\dotsc,x_{ik}]^T\\in\\mathbb R^{ (k+1)}$)\n",
    "$$y_i = x_i^T\\beta+\\epsilon_i.$$\n",
    "\n",
    "Still we assume that the noise is independent with $\\mathbb E(\\epsilon_i )=0$ and ${\\rm Var}(\\epsilon_i)=\\sigma^2$.\n",
    "\n",
    "<br>\n",
    "\n",
    "We can stack all $n$ observations by matrices,\n",
    "$y = [y_1,\\dotsc,y_n]\\in\\mathbb R^n$, $X = [x_1,\\dotsc,x_{n}]^T\\in\\mathbb R^{n\\times (k+1)}$ and $\\epsilon=[\\epsilon_1,\\dotsc,\\epsilon_n]\\in\\mathbb R^n$. As a consequence, $\\mathbb E(Y) =X\\beta$ and ${\\rm Cov}(Y) = \\sigma^2I_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Least Squares Estimator\n",
    "\n",
    "$${\\rm argmin}_{\\hat \\beta} \\Vert y - X\\hat \\beta\\Vert^2\\quad\\Leftrightarrow\\quad X^TX\\hat\\beta = X^Ty $$\n",
    "\n",
    "Proof: For arbitrary $b\\in\\mathbb R^{k+1}$,\n",
    "$$\\Vert y - Xb\\Vert^2-\\Vert y -X\\hat\\beta\\Vert^2\n",
    "=\\Vert (y - X\\hat\\beta)+X(\\hat\\beta -b)\\Vert^2 - \\Vert y - X\\hat \\beta\\Vert^2\n",
    "=2(y-X\\hat\\beta)^TX(\\hat \\beta - b)+\\Vert X(\\hat\\beta -b)\\Vert^2.$$\n",
    "\n",
    "In particular, if $X^TX\\hat\\beta = X^Ty$, we have $2(y-X\\hat\\beta)^TX=0$ and thus, \n",
    "$$\\Vert y - Xb\\Vert^2-\\Vert y -X\\hat\\beta\\Vert^2\\geqslant 0.$$\n",
    "\n",
    "Such $\\hat \\beta$ always exists, and one of the solutions is given by $\\hat \\beta = X^\\dag y$ where $X^\\dag$ is the pseudoinverse.\n",
    "\n",
    "However, we shall further assume $X^TX$ is nonsingular and $\\hat\\beta =(X^TX)^{-1}X^Ty$.\n",
    "\n",
    "In this case, \n",
    "\n",
    "$${\\rm Cov}(\\hat \\beta) = {\\rm Cov}((X^TX)^{-1}X^T(X\\beta + \\epsilon))\n",
    "= {\\rm Cov}((X^TX)^{-1}X^T\\epsilon)=\\sigma^2(X^TX)^{-1}.$$\n",
    "\n",
    "Here we have used the fact that ${\\rm Cov}(Au) = A{\\rm Cov}(u)A^T$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1120dc956da57eca5c948a0118f4cdcd4d1b3be98c72752ed298d16085a61d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
