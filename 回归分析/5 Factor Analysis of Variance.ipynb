{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Factor Analysis of Variance\n",
    "\n",
    "By \"factor\" we mean a **discrete** covariate (e.g. categories) and by \"factor level\" a particular value (category) of factor. \n",
    "\n",
    "## Single Factor\n",
    "\n",
    "### Model\n",
    "\n",
    "Assume we are focusing on a factor $A$, which has $r$ different categories, indexed by $A_1,A_2,\\dotsc,A_r$. For factor being the $A_i$, we have observations $y_{i1},y_{i2},\\dotsc,y_{i,n_i}\\in\\mathbb R^k$. Assume these observations are from $N(\\mu_i,\\Sigma)$.\n",
    "\n",
    "In total there are $n_1+\\dotsc+n_r=n$ observations. The variance $\\Sigma $ is independent with the factor.\n",
    "\n",
    "### Notations\n",
    "\n",
    "Sample mean of class $A_i$ is \n",
    "$$\\bar y_{i\\cdot} = \\frac {1}{n_i}\\sum_{j=1}^{n_i}y_{ij}=\\frac{1}{n_i}\\sum_{j=1}^n(\\mu_i + \\epsilon_{ij}) = \\mu_i +\\bar \\epsilon_{i\\cdot}.\n",
    "$$\n",
    "\n",
    "The sample mean of all data is\n",
    "$$\\bar y_{\\cdot \\cdot} = \\frac {1}{n}\\sum_{i=1}^r\\sum_{j=1}^{n_i}y_{ij}=\\left(\\frac {1}{n}\\sum_{i=1}^rn_i\\mu_i \\right)+\\bar{\\epsilon_{\\cdot \\cdot}}.\n",
    "$$\n",
    "\n",
    "### Estimators \n",
    "\n",
    "For each $i$, it is clear that the least squares estimator or MLE for mean is given by $\\hat\\mu_i = \\bar y_{i\\cdot}$. For $\\Sigma$, the MLE should be:\n",
    "$$\\hat\\Sigma ={\\rm argmin}\\sum_{i=1}^r\\sum_{j=1}^{n_i} \\left(-\\frac 12(y_{ij} - \\hat\\mu_i)^T\\Sigma^{-1}(y_{ij} - \\hat\\mu_i)- \\frac k2\\log(2\\pi ) +\\frac12\\log |\\Sigma^{-1}|\\right).\n",
    "$$\n",
    "\n",
    "#### Scalar Observations\n",
    "\n",
    "In particular, if $y\\in\\mathbb R$ is a scalar, and the variance $\\Sigma = \\sigma^2$ is also a scalar. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA\n",
    "\n",
    "### Sum of Squares \n",
    "\n",
    "Define the total sum of squares to be ${\\rm SST} = \\sum_{i,j}(y_{ij} - y_{\\cdot \\cdot})^2$, and then\n",
    "$${\\rm SST} = \\sum_{i=1}^r \\sum_{j=1}^{n_i}\\left[(y_{ij} - \\bar y_{i\\cdot})^2+(\\bar y_{i\\cdot} - \\bar y_{\\cdot \\cdot})^2+2(y_{ij} - \\bar y_{i\\cdot})(\\bar y_{i\\cdot} - \\bar y_{\\cdot \\cdot})\\right]=\\sum_{i=1}^r \\sum_{j=1}^{n_i}\\left[(y_{ij} - \\bar y_{i\\cdot})^2+(\\bar y_{i\\cdot} - \\bar y_{\\cdot \\cdot})^2\\right].$$\n",
    "\n",
    "We then define ${\\rm SSE} = S_e = \\sum_{i=1}^r \\sum_{j=1}^{n_i}(y_{ij} - \\bar y_{i\\cdot})^2$ and ${\\rm SSR} = S_A = \\sum_{i=1}^r \\sum_{j=1}^{n_i}(\\bar y_{i\\cdot} - \\bar y_{\\cdot \\cdot})^2=n_i\\sum_{i=1}^r(\\bar y_{i\\cdot} - \\bar y_{\\cdot \\cdot})^2$. We can see that ${\\rm SSE}$ stands for the within-group error, while ${\\rm SSR}$ is the between-group variation.\n",
    "\n",
    "Since we know that we can find $\\sigma^2\\chi_{n_i-1}^2 =\\sum_{j=1}^{n_i}(y_{ij} - \\bar y_{i\\cdot})^2 $ such that $\\chi_{n_i-1}^2$ is independent with $\\bar y_{i\\cdot}$, so\n",
    "$$S_e \\sim \\sum_{i=1}^r  \\sigma^2 \\chi_{n_i-1}^2=\\sigma^2 \\chi_{n-r}^2  \\perp\\!\\!\\!\\!\\!\\!\\perp S_A.$$\n",
    "\n",
    "\n",
    "#### ANOVA\n",
    "\n",
    "If we want to test $H_0:\\ \\mu_1=\\mu_2=\\dotsc=\\mu_n$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.4 (tags/v3.8.4:dfa645a, Jul 13 2020, 16:46:45) [MSC v.1924 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1120dc956da57eca5c948a0118f4cdcd4d1b3be98c72752ed298d16085a61d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
