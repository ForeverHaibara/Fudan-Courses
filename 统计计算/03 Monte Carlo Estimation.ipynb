{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Monte Carlo Estimation\n",
    "\n",
    "## Expectation and Variance\n",
    "\n",
    "We can use Monte Carlo to estimate the expectation and the variance of a distribution.\n",
    "\n",
    "**Example** $A,B\\sim N(0,1)$ are independent. Estimate the expectation and the variance of $|A-B|$.\n",
    "\n",
    "We can generate $m$ samples $(a_i,b_i)$.\n",
    "\n",
    "$$\\begin{aligned} \\mathbb E|A-B|\\approx \\frac 1m\\sum_{i=1}^m |a_i-b_i|\n",
    "\\quad\\quad\\text{and}\\quad\\quad \\text{Var}|A-B|\\approx {\\frac 1m\\sum_{i=1}^m |a_i-b_i|^2-\\left(\\frac 1m\\sum_{i=1}^m |a_i-b_i|\\right)^2}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Note: true values are given by $\\mathbb E|A-B|=\\frac{2}{\\sqrt\\pi}\\approx 1.1284$ and $\\text{Var}|A-B|=\\frac{2\\pi -4}{\\pi}\\approx 0.7268$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E   =  1.127735953938156 \n",
      "Var =  0.7105818062739038\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "m = 10000\n",
    "samples = np.random.randn(2, m)\n",
    "samples = np.abs(samples[0] - samples[1])\n",
    "E = np.mean(samples)\n",
    "Var = np.mean(samples**2) - E**2\n",
    "print(\"E   = \", E, \"\\nVar = \", Var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimmed Mean\n",
    "\n",
    "Sometimes we can use trimmed mean to estimate the expectation. To be specific, if we have $n$ samples sorted as $X_{(1)}\\leqslant X_{(2)}\\leqslant\\cdots\\leqslant X_{(n)}$ (ordered statistics), then the trimmed mean is defined as\n",
    "\n",
    "$$\\bar X_{[-k]} = \\frac 1{n-2k}\\sum_{i=k+1}^{n-k}X_{(i)}.$$\n",
    "\n",
    "That is to discard the smallest $k$ and the largest $k$ samples. This avoids the influence of outliers.\n",
    "\n",
    "<br>\n",
    "\n",
    "To estimate the MSE of the method of trimmed mean on a certain problem, we can repeat multiple times and calculate the MSE of the results. It is expected that trimmed mean helps reduce MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =   0  MSE = 0.011051793687713337\n",
      "k =  10  MSE = 0.008204855245958247\n",
      "k =  50  MSE = 0.0017579262863889676\n",
      "k = 450  MSE = 0.0017558976326968272\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "def noised_gaussian(n, p = .9, var1 = 1, var2 = 100):\n",
    "    # A mixed gaussian distribution that has probability p to be N(0, var1) and 1-p to be N(0, var2).\n",
    "    ps = np.random.random(n) < p\n",
    "    samples = np.random.randn(n)\n",
    "    samples = np.where(ps, samples * np.sqrt(var1), samples * np.sqrt(var2))\n",
    "    return samples\n",
    "\n",
    "def trimed_mean(samples, k = 0):\n",
    "    if k == 0: return np.mean(samples)\n",
    "    samples = np.sort(samples)\n",
    "    return np.mean(samples[k : -k])\n",
    "\n",
    "def simulate_trimed_mean_MSE(distribution, estimator, n = 1000, times = 1000, true_value = 0.):\n",
    "    s = 0\n",
    "    for time_ in range(times):\n",
    "        s += (estimator(distribution(n)) - true_value)**2\n",
    "    return s / times\n",
    "\n",
    "# test trimmed mean with different k\n",
    "for k_ in [0, 10, 50, 450]:\n",
    "    estimator = partial(trimed_mean, k = k_)\n",
    "    print(\"k = %3d \"%k_, \"MSE =\", simulate_trimed_mean_MSE(noised_gaussian, estimator, n = 1000, true_value = 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "### Confidence Level\n",
    "\n",
    "When asymptotic normality is assumed, we can simply use $\\bar X\\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n}$ to construct a confidence interval.\n",
    "\n",
    "However, when normality is not available, we can use Monte Carlo to determine the confidence level of a confidence interval. Repeatedly compute the confidence interval multiple times on different samples, and calculate the proportion of the confidence intervals that contain the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Confidence Level = 0.948\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2, norm\n",
    "\n",
    "def distribution(n = 1000):\n",
    "    return np.random.randn(n) * 2 # variance = 4\n",
    "\n",
    "# estimate the CI for the variance of the normal distribution\n",
    "def estimator(samples):\n",
    "    # P((n-1)Var / sigma^2 > t) = P(chi^2(n-1) > t) = .95\n",
    "    # <=> sigma^2 < (n-1)Var / t\n",
    "    S = ((samples - samples.mean())**2).sum()\n",
    "    r_bound = (S / chi2.ppf(.05, samples.size-1)) ** .5\n",
    "    return (0, r_bound)\n",
    "\n",
    "def estimate_confidence_level(distribution, estimator, n = 20, times = 1000, true_value = 2.):\n",
    "    s = 0\n",
    "    for time_ in range(times):\n",
    "        l, r = estimator(distribution(n))\n",
    "        if l <= true_value <= r:\n",
    "            s += 1\n",
    "    return s / times\n",
    "\n",
    "print('Estimated Confidence Level =', estimate_confidence_level(distribution, estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power and Type II Error\n",
    "\n",
    "Consider the following hypothesis testing problem.\n",
    "\n",
    "$$\\begin{aligned} H_0: \\theta\\in\\Theta_0\\quad\\quad\\text{vs.}\\quad\\quad H_1: \\theta\\notin\\Theta_0 \\end{aligned}$$\n",
    "\n",
    "Given observed data $X$, we can reject $H_0$ if $\\sup_{\\theta\\in\\Theta_0}L(\\theta|X)<c$ for some $c$. The probability of rejecting $H_0$ when $H_0$ is true is called the **Type I error**. The probability of rejecting $H_0$ when $H_0$ is false is called the **power**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness Test\n",
    "\n",
    "Let $X$ be a random variable. Its skewness is defined by\n",
    "\n",
    "$$\\text{Skew}(X)=\\frac{\\mathbb E(X-\\mu)^3}{\\sigma^3}$$\n",
    "\n",
    "where $\\mu$ and $\\sigma$ are the mean and the standard deviation of $X$. If $\\text{Skew}(X)=0$, then $X$ is symmetric. When $\\text{Skew}(X)>0$, then $X$ is right-skewed. When $\\text{Skew}(X)<0$, then $X$ is left-skewed.\n",
    "\n",
    "**Theorem** Let $\\kappa_r = \\mathbb E(X - \\mathbb EX)^r$ to be the central moment. Suppose $\\kappa_6$ is finite. Define\n",
    "\n",
    "$$b = \\frac{\\frac 1n\\sum_{i=1}^n (X_i - \\bar X)^3}{\\left[\\frac 1n\\sum_{i=1}^n (X_i - \\bar X)^2\\right]^{\\frac 32}}.$$\n",
    "\n",
    "Then we have asymptotic normality $\\sqrt n (b- \\text{Skew}(X))\\to N(0,v)$ where \n",
    "\n",
    "$$v =\\frac{36 \\kappa_{2}^{5} - 24 \\kappa_{2}^{3} \\kappa_{4} + 35 \\kappa_{2}^{2} \\kappa_{3}^{2} + 4 \\kappa_{2}^{2} \\kappa_{6} - 12 \\kappa_{2} \\kappa_{3} \\kappa_{5} + 9 \\kappa_{3}^{2} \\kappa_{4}}{4 \\kappa_{2}^{5}}.$$\n",
    "\n",
    "In particular, if $X$ is normal, then $v=6$.\n",
    "\n",
    "**Proof** From [https://marcgenton.github.io/2021.AHG.bookchap.pdf](https://marcgenton.github.io/2021.AHG.bookchap.pdf) we have the following result of joint asymptotic normality (note that $\\kappa_1 = 0$):\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\sqrt n \\left[\\begin{matrix}\\frac 1n\\sum_{i=1}^n (X_i - \\bar X)^2- \n",
    "\\kappa_2\\\\ \\frac 1n\\sum_{i=1}^n (X_i - \\bar X)^3 - \\kappa_3\n",
    "\\end{matrix}\\right]\\rightarrow_d N\\left\\{\\mathbf 0,\n",
    "\\left[\\begin{matrix}- \\kappa_{2}^{2} + \\kappa_{4} & - 4 \\kappa_{2} \\kappa_{3} + \\kappa_{5}\\\\- 4 \\kappa_{2} \\kappa_{3} + \\kappa_{5} & 9 \\kappa_{2}^{3} - 6 \\kappa_{2} \\kappa_{4} - \\kappa_{3}^{2} + \\kappa_{6}\\end{matrix}\\right]\n",
    "\\right\\}\n",
    "\\end{aligned}.$$\n",
    "\n",
    "Apply the Slutsky theorem: if $\\sqrt n(Y -c)\\rightarrow_d N(0,\\Sigma)$, then $\\sqrt n(g(Y) -g(c))\\rightarrow_d N(0,\\nabla g(c)^T\\Sigma \\nabla g(c))$. Taking $g = \\left[\\begin{matrix}x_1\\\\ x_2\\end{matrix}\\right]\\mapsto  {x_2}{x_1^{-\\frac 32}}$ yields the result.\n",
    "\n",
    "<!-- $Y=\\left[\\begin{matrix}\\frac 1n\\sum_{i=1}^n (X_i - \\bar X)^2\\\\ \\frac 1n\\sum_{i=1}^n (X_i - \\bar X)^3\\end{matrix}\\right]$ and $c=\\left[\\begin{matrix}\\kappa_2\\\\ \\kappa_3\\end{matrix}\\right]$ -->\n",
    "\n",
    "In particular, for normal distribution $X\\sim N(0,\\sigma^2)$, $\\kappa_r = \\sigma^r (r-1)!!$ for even $r$ while $\\kappa_r = 0$ for odd $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var =\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{36 \\kappa_{2}^{5} - 24 \\kappa_{2}^{3} \\kappa_{4} + 35 \\kappa_{2}^{2} \\kappa_{3}^{2} + 4 \\kappa_{2}^{2} \\kappa_{6} - 12 \\kappa_{2} \\kappa_{3} \\kappa_{5} + 9 \\kappa_{3}^{2} \\kappa_{4}}{4 \\kappa_{2}^{5}}$"
      ],
      "text/plain": [
       "(36*\\kappa_2**5 - 24*\\kappa_2**3*\\kappa_4 + 35*\\kappa_2**2*\\kappa_3**2 + 4*\\kappa_2**2*\\kappa_6 - 12*\\kappa_2*\\kappa_3*\\kappa_5 + 9*\\kappa_3**2*\\kappa_4)/(4*\\kappa_2**5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "from IPython.display import display, Math\n",
    "\n",
    "x, y, sigma = sp.symbols('x y \\\\sigma', real = True, positive = True)\n",
    "# central moments of the normal distribution\n",
    "moments = [(sigma**n * sp.factorial2(n-1)) if n % 2 == 0 else 0 for n in range(10)]\n",
    "moments_std = [sp.Symbol(f'\\\\kappa_{i}') for i in range(10)]\n",
    "\n",
    "def get_S(inds, moments = None):\n",
    "    \"\"\"\n",
    "    Return the covariance matrix of the sample central moments of order = inds.\n",
    "    See Preposition 2 at https://marcgenton.github.io/2021.AHG.bookchap.pdf\n",
    "\n",
    "    Parameter `moments` is a list that moments[i] = E((X - \\mu)^i).\n",
    "    \"\"\"\n",
    "    inds = list(inds)\n",
    "    m = max(inds)\n",
    "    if moments is None:\n",
    "        moments = [sp.Symbol(f'\\\\kappa_{i}') for i in range(2*m+1)]\n",
    "    moments[0] = 1\n",
    "    # moments[1] = 0\n",
    "    S = sp.zeros(m, m)\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            # S[i,j] = Cov(E[X^(i+1)], E[X^(j+1)]) where X is centered\n",
    "            S[i, j] = moments[i+j+2] - moments[i+1] * moments[j+1]\n",
    "\n",
    "    C = sp.eye(m)\n",
    "    for i in range(1, m):\n",
    "        C[i, 0] = -(i+1) * moments[i]\n",
    "    S = C * S * C.T\n",
    "    inds = [i-1 for i in inds]\n",
    "    return S[inds, :][:, inds]\n",
    "\n",
    "func = y / x**sp.Rational(3,2)\n",
    "value = {x: sp.Symbol('\\\\kappa_2'), y: sp.Symbol('\\\\kappa_3')}\n",
    "grad = sp.Matrix([func.diff(x), func.diff(y)])\n",
    "S = get_S([2,3], moments = None).expand()\n",
    "var = (grad.T * S * grad)[0,0].subs(value).factor() # apply Slutsky's theorem\n",
    "var = var.subs(sp.Symbol('\\\\kappa_1'), 0).factor()\n",
    "print('Var =')\n",
    "display(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Cov =\n",
      "[[ 2.05168495 -0.05066736]\n",
      " [-0.05066736  6.09908922]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "s = {2: [], 3: []}\n",
    "n = 1000\n",
    "for time in range(5000):\n",
    "    samples = np.random.randn(n) \n",
    "    samples -= samples.mean()\n",
    "    for i in (2,3):\n",
    "        s[i].append((samples**i).mean())\n",
    "\n",
    "print('Sample Cov =\\n%s'%(np.cov(np.array(list(s.values())) * n **.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Reinaldo B. Arellano-Valle, Simone B. Harnik, and Marc G. Genton, [On the Asymptotic Joint Distribution of Multivariate Sample Moments](https://marcgenton.github.io/2021.AHG.bookchap.pdf), In: Ghosh, I., Balakrishnan, N., Ng, H.K.T. (eds) Advances in Statistics - Theory and Applications. Emerging Topics in Statistics and Biostatistics . Springer, Cham.\n",
    "\n",
    "[2] [https://math.stackexchange.com/questions/92648/calculation-of-the-n-th-central-moment-of-the-normal-distribution-mathcaln](https://math.stackexchange.com/questions/92648/calculation-of-the-n-th-central-moment-of-the-normal-distribution-mathcaln)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
