{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Matching\n",
    "\n",
    "Recall the idea in the chapter of propensity score, some data have extreme propensity scores and should be discarded. A similar idea is used in matching. We match treated data and controlled data into pairs. And then we discard data that are not matched. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Matching\n",
    "\n",
    "Assume the confounding variable $c\\in C$ is discrete (categorical) variable. For each treated units $w_1,\\dotsc,w_n$, we find a control unit $w_i^*$ such that $c(w_i)=c(w_i^*)$ for $j=1,\\dotsc,n$. If there are multiple control units, we choose one of them randomly. The matched control units are denoted by $w_1^*,\\dotsc,w_n^*$.\n",
    "\n",
    "**The unmatched control units are discarded.** The matched data set is $\\{(w_1,w_1^*), \\dotsc, (w_n,w_n^*)\\}$.\n",
    "\n",
    "For a control unit $w$, denote $I(w)= 1$ if $w$ is matched and $0$ otherwise. \n",
    "\n",
    "After exact matching, we can assume that\n",
    "\n",
    "$$\\mathbb P(c|A=1)=\\mathbb P(c|A=0,\\ I=1)$$\n",
    "\n",
    "\n",
    "\n",
    "### Coarsened Exact Matching\n",
    "\n",
    "For continous variables, we can perform stratification to convert them to discrete variables. Note that stratification faces bias-variance tradeoff. More strata leads to less bias but larger variance. \n",
    "\n",
    "This is known as coarsened exact matching (CEM).\n",
    "\n",
    "### Average Treatment Effect of Treated\n",
    "\n",
    "Average treatment effect of treated (ATT) is defined as\n",
    "$$\\text{ATT}=\\mathbb E[Y^1 - Y^0|A=1].$$\n",
    "\n",
    "\n",
    "Similarly we can define the average treatment of controlled (ATC):\n",
    "$$\\text{ATC}=\\mathbb E[Y^1 - Y^0|A=0].$$\n",
    "\n",
    "\n",
    "### Average Treatment Effect\n",
    "\n",
    "Having computed $\\text{ATT}$ and $\\text{ATC}$, we can compute the average treatment effect (ATE):\n",
    "\n",
    "$$\\begin{aligned}\\text{ATE}&=\\mathbb E[Y^1 - Y^0] = \\mathbb E[Y^1 - Y^0|A=1]\\cdot \\mathbb P(A=1) + \\mathbb E[Y^1 - Y^0|A=0]\\cdot\\mathbb P(A=0)\\\\ &= \\text{ATT}\\cdot \\mathbb P(A=1) + \\text{ATC}\\cdot \\mathbb P(A=0)\\end{aligned}$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Estimator\n",
    "\n",
    "When we use the exact matching, we have \n",
    "$$\\widehat{\\text{ATT}} = \\widehat{\\mathbb E}[Y^1-Y^0|A=1] = \\frac{1}{n}\\sum_{i=1}^n(Y_i - Y_i^*).$$\n",
    "\n",
    "The variance is estimated by \n",
    "$$\\widehat{\\text{Var}}(\\widehat{\\text{ATT}}) = \\frac{1}{n}\\sum_{i=1}^n(Y_i - Y_i^* - \\widehat{\\text{ATT}})^2.$$\n",
    "\n",
    "<br>\n",
    "\n",
    "### Other Matching Methods\n",
    "\n",
    "If the control units are adequate, we can match each treated unit to multiple controls. \n",
    "\n",
    "Another problem is whether match the control units with replacement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inexact Matching\n",
    "\n",
    "Instead of matching exact confounding variables, we can match any units with close confounding variables.\n",
    "\n",
    "### Distance\n",
    "\n",
    "We shall define the distance between confounding variables.\n",
    "\n",
    "#### Propensity Score Distance\n",
    "\n",
    "Recall we can fit a logistic regression for propensity score: $e(c) = \\mathbb P(A=1|C=c) = \\frac{1}{1+\\exp(-\\beta_0-\\beta^Tc)}$. Then, we use \n",
    "\n",
    "$$\\text{dist}(c_1,c_2) = |\\beta^T(c_1 - c_2)|.$$\n",
    "\n",
    "It is the distance between the logit of propensity scores.\n",
    "\n",
    "#### Mahalanobis Distance\n",
    "\n",
    "We can also use Mahalanobis distance. Let $\\Sigma$ to be the covariance matrix of confounding variables of each unit, where $\\Sigma_{ij} = {\\rm Cov}(c_i,c_j)$.\n",
    "\n",
    "$$\\text{dist}(c_1,c_2) = \\sqrt{(c_1-c_2)^T\\Sigma^{-1}(c_1-c_2)}.$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Correction\n",
    "\n",
    "Fit a model $\\mu_0(c) = \\mathbb E(Y^0|C=c)$, representing the effect of $c$ on $Y^0$. We will now assume $\\mu_0$ is linear, i.e. $\\mu_0(c) = \\beta_0 + \\beta^Tc$. For each pair of matched units $(w_i,w_i^*)$, we have \n",
    "$${\\text{ATT}}_i = \\mathbb E(Y_i^1 - Y_i^0)=\\mathbb E(Y_i^1 - Y_i^{*0}) +\\mathbb E( Y_i^{*0}-Y_i^0)=\\widehat{\\text{ATT}}_i+(\\mu_0(c_i^*) - \\mu_0(c_i)).$$\n",
    "\n",
    "The final term $(\\mu_0(c_i^*) - \\mu_0(c_i))=\\beta^T(c_i^*-c_i)$ is the bias. We can correct the bias by adding it to the estimator $\\widehat{\\text{ATT}}_i$:\n",
    "$$\\widehat{\\text{ATT}}_{i\\ \\text{bc}} = \\widehat{\\text{ATT}}_i + \\beta^T(c_i^*-c_i).$$\n",
    "\n",
    "As a result, the overall estimators are \n",
    "$$\\left\\{\\begin{aligned} &\n",
    "\\widehat{\\text{ATT}}_{\\text{bc}}= \\frac{1}{n}\\sum_{i=1}^n\\widehat{\\text{ATT}}_{i\\ \\text{bc}}\\\\  &\n",
    "\\widehat{\\text{Var}}(\\widehat{\\text{ATT}}_{\\text{bc}})= \\frac{1}{n}\\sum_{i=1}^n(\\widehat{\\text{ATT}}_{i\\ \\text{bc}} - \\widehat{\\text{ATT}}_{\\text{bc}})^2.\n",
    "\\end{aligned}\\right.$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
