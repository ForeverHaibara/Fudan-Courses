{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krylov 子空间\n",
    "\n",
    "记号. $\\mathcal K(A,x,k) = {\\rm span}\\{x,Ax,A^2x,\\dotsc,A^{k-1}x\\}$ 称为一个 Krylov 子空间.\n",
    "\n",
    "**Theorem 1** $\\mathcal K(A,x,k)\\subset K(A,x,k+1)$.\n",
    "\n",
    "**Theorem 2** 若 $A$ 的极小多项式次数为 $k$, 则 $\\forall m\\geqslant k$, $\\mathcal K(A,x,m) =\\mathcal K(A,x,k)$.\n",
    "\n",
    "证: 假设极小多项式为 $$A^k + a_{k-1}A^{k-1} + \\dotsc + a_1A + a_0I = O$$\n",
    "那么显然 $A^kx$ 可以由 $x,Ax,\\dotsc,A^{k-1}x$ 线性表出. 同理 $\\forall m, A^mx$ 也可以.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Arnoldi 过程\n",
    "\n",
    "目标: 矩阵 $A$ 是 $n\\times n$ 的方阵, 求得 $n\\times (k+1) $ 的正交列向量构成的矩阵\n",
    " $Q_{k+1} = [q_1,q_2\\dotsc,q_{k+1}]$ , 使得 \n",
    "$AQ_k = Q_{k+1}\\widetilde H_k$.\n",
    "\n",
    "其中 $Q_k =  [q_1,q_2\\dotsc,q_{k}]$ 是前 $k$ 列. 而 $\\widetilde H_k$ 是如下结构的上 Hessenberg 矩阵:\n",
    "\n",
    "$$\\widetilde H_k = \\left[\\begin{matrix} h_{11}  &  h_{12} &  \\dotsc  &  h_{1,k-1} &  h_{1k} \\\\\n",
    " h_{21} &  h_{22}  &  \\dotsc  &  h_{2,k-1} &  h_{2k} \\\\\n",
    "\\ &  h_{32}  &  \\dotsc  &  h_{3,k-1}  &  h_{3k} \\\\\n",
    "\\ &   & \\ddots &\\vdots & \\vdots\\\\\n",
    "\\ &   &   &  h_{k,k-1}  &  h_{kk} \\\\\n",
    "\\ &   &   &   &  h_{k+1,k} \\end{matrix}\\right]\\in \\mathbb C^{(k+1)\\times k}.$$\n",
    "\n",
    "而\n",
    "\n",
    "$$AQ_k = [Aq_1,Aq_2,\\dotsc,Aq_k] = [q_1,q_2,\\dotsc,q_k]\\widetilde H_k.$$\n",
    "\n",
    "显然 $Aq_1$ 是 $q_1,q_2$ 的线性组合, $Aq_2$ 是 $q_1,q_2,q_3$ 的线性组合 ... $Aq_k$ 是 $q_1,\\dotsc ,q_{k+1}$ 的线性组合. 因此 \n",
    "$AQ_k = Q_{k+1}\\widetilde H_k$ 也可写作 $$AQ_k = Q_kH_k + h_{k+1,k} q_{k+1}e_k^*.$$\n",
    "\n",
    "从而\n",
    "\n",
    "$$Q_k^*AQ_k = H_k.$$\n",
    "\n",
    "<br>\n",
    "\n",
    "从线性组合的角度, 容易发现求解 $q_{k+1}$ 的步骤与 Gram-Schmidt 相近:\n",
    "$$Aq_k = h_{1k}q_1 + h_{2k}q_2 +\\dotsc + h_{kk}q_k + h_{k+1,k}q_{k+1}.$$\n",
    "$$h_{ik} = q_i^*Aq_k\\quad (i\\leqslant k).$$\n",
    "$$h_{k+1,k}q_{k+1} = Aq_k - \\sum_{i=1}^k h_{ik}q_i.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonaliy Loss = 3.931522835259797e-15\n",
      "||Q*AQ - H|| = 2.865885625235656e-14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 找到 Q,H 使得 Q^* A Q = H\n",
    "def Arnoldi(A,k=-1):\n",
    "    n = A.shape[0]\n",
    "    if k < 0 or k > n: k = n\n",
    "    Q = np.zeros((n,k),dtype=A.dtype)\n",
    "    H = np.zeros((k,k),dtype=A.dtype)\n",
    "    # 初始化第一列\n",
    "    Q[:,0] = np.random.randn(n)\n",
    "    Q[:,0] /= np.linalg.norm(Q[:,0])\n",
    "    for i in range(k):\n",
    "        H[:i+1,i] = Q[:,:i+1].T.conj() @ A @ Q[:,i]\n",
    "        if i + 1 < k :\n",
    "            Q[:,i+1] = A @ Q[:,i] - Q[:,:i+1] @ H[:i+1,i]\n",
    "            H[i+1,i] = np.linalg.norm(Q[:,i+1])\n",
    "            Q[:,i+1] /= H[i+1,i]\n",
    "    return Q , H\n",
    "\n",
    "\n",
    "n , k = 50 , 30\n",
    "np.random.seed(0)\n",
    "A = (np.random.randn(n*n)+np.random.randn(n*n)*1j).reshape((n,n))\n",
    "Q, H = Arnoldi(A,30)\n",
    "print('Orthogonaliy Loss =',np.linalg.norm(Q.T.conj() @ Q - np.eye(k)))\n",
    "print('||Q*AQ - H|| =',np.linalg.norm(Q.T.conj() @ A @ Q - H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归纳易见 Arnoldi 过程中, \n",
    "$${\\rm span}\\{q_1,q_2,\\dotsc,q_k\\} = {\\rm span}\\{q_1,Aq_1,\\dotsc,A^{k-1}q_1\\} = \\mathcal K(A,q_1,k).$$\n",
    "\n",
    "特别地, 由 **Theorem 2**, 若设 $A$ 的极小多项式次数为 $m$, 则$${\\rm span}\\{q_1,q_2,\\dotsc,q_{m+1}\\} ={\\rm span}\\{q_1,q_2,\\dotsc,q_{m}\\}.$$\n",
    "\n",
    "但 $q_{m+1}$ 应与 $q_i\\ (i\\leqslant m)$ 均正交, 这说明 $q_{m+1} = 0$. 即 Arnoldi 过程终止. 此时 $AQ_m = Q_mH_m$, 其中 $H_m\\in \\mathbb C^{m\\times m}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMRES\n",
    "\n",
    "对于方程 $Ax = b$, 可以按如下方法求得近似解. 假设 Arnoldi 过程得到 $AQ_k = Q_{k+1}\\widetilde H_k$. 若存在 $x_0$, 使 $q_1 = \\frac{b-Ax_0}{\\Vert b- Ax_0\\Vert_2}=\\frac{r_0}{\\Vert r_0\\Vert_2}$, 则 \n",
    "$${\\rm span}\\{q_1,\\dotsc,q_k\\} = \\mathcal K(A,r_0,k).$$\n",
    "\n",
    "在子空间 $x_0+\\mathcal K(A,r_0,k)$ 中求解最小二乘问题 $\\Vert Ax - b\\Vert$:\n",
    "$$\\Vert A(x_0 + Q_ky) - b\\Vert_2 = \\Vert Q_{k+1}\\widetilde H_ky - r_0 \\Vert_2\n",
    "=\\Vert \\widetilde H_ky - \\beta e_1\\Vert_2.$$\n",
    "\n",
    "最后一步是因为 $r_0$ 与 $Q_{k+1}$ 第一列平行, 故 $Q_{k+1}^*r_0 = \\beta e_1$, 其中 $\\beta = \\Vert r_0\\Vert_2$.\n",
    "\n",
    "$\\Vert \\widetilde H_ky - \\beta e_1\\Vert_2$ 的最小值还是最小二乘问题, 而 $\\widetilde H_k$ 是 Hessenberg 矩阵, 可以通过 $k$ 次 Givens 变换变成上三角阵形成 QR 分解. 详见 [2] p. 643."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lanczos 过程\n",
    "\n",
    "若 $A$ 是 Hermite 矩阵, 则 $H_k = Q_k^*AQ_k$ 是 Hermite 的上 Hessenberg 矩阵, 因此必为三对角矩阵. 此时的 Arnoldi 过程称为 Lanczos 过程.\n",
    "\n",
    "$$AQ_k = Q_k\\left[\\begin{matrix} \\alpha_1  &  \\beta_1 &   &  & \\\\\n",
    " \\beta_1 & \\alpha_2 & \\beta_2 &   & \\\\\n",
    "\\ &  \\beta_2  &  \\alpha_3 &  \\ddots &   \\\\\n",
    "\\ &   & \\ddots &\\ddots & \\beta_{k-1} \\\\\n",
    "\\ &   &   &  \\beta_{k-1}  &  \\alpha_{k} \\\\\n",
    "\\ &   &   &   &  \\beta_k \\end{matrix}\\right].$$\n",
    "\n",
    "可见, $Aq_k = \\beta_{k-1}q_{k-1}+\\alpha_kq_k +\\beta_{k}q_{k+1}\\ (k>1)$, 故 \n",
    "$$\\alpha_k = q_k^*Aq_k$$\n",
    "$$\\beta_kq_{k+1} = Aq_k - \\beta_{k-1}q_{k-1} -\\alpha_kq_k$$\n",
    "\n",
    "这是短递推, 有如下优点:\n",
    "1. 如果只需要求 $H_k$ 而不需要正交矩阵, 则无需记录所有 $q$, 因为每步只用到上两个 $q$: $q_{k-1},q_k$. 节省内存.\n",
    "2. 运算量少, 效率高.\n",
    "\n",
    "但相比一般的 Arnoldi 也有缺点:\n",
    "1. 计算时默认且利用了列向量正交的假设, 但舍入误差的存在会使正交阵的正交性逐渐变差."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonaliy Loss = 1.6302096042761702e-10\n",
      "||Q*AQ - H|| = 2.1444299264284427e-09\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 找到 Q,H 使得 Q^* A Q = H , 需要 A 是 Hermite矩阵\n",
    "def Lanczos(A,k=-1):\n",
    "    n = A.shape[0]\n",
    "    if k < 0 or k > n: k = n\n",
    "    Q = np.zeros((n,k),dtype=A.dtype)\n",
    "    H = np.zeros((k,k),dtype=A.dtype)\n",
    "    # 初始化第一列\n",
    "    Q[:,0] = np.random.randn(n)\n",
    "    Q[:,0] /= np.linalg.norm(Q[:,0])\n",
    "    for i in range(k):\n",
    "        H[i,i] = Q[:,i].T.conj() @ A @ Q[:,i] \n",
    "        if i + 1 < k :\n",
    "            Q[:,i+1] = A @ Q[:,i] - H[i,i] * Q[:,i]\n",
    "            if i > 0:\n",
    "                Q[:,i+1] -= H[i,i-1] * Q[:,i-1]\n",
    "            H[i+1,i] = np.linalg.norm(Q[:,i+1])\n",
    "            H[i,i+1] = H[i+1,i]\n",
    "            Q[:,i+1] /= H[i+1,i]\n",
    "    return Q , H\n",
    "\n",
    "\n",
    "n , k = 50 , 30\n",
    "np.random.seed(0)\n",
    "A = (np.random.randn(n*n)+np.random.randn(n*n)*1j).reshape((n,n))\n",
    "A = (A + A.T.conj()) * 0.5\n",
    "Q, H = Lanczos(A,30)\n",
    "print('Orthogonaliy Loss =',np.linalg.norm(Q.T.conj() @ Q - np.eye(k)))\n",
    "print('||Q*AQ - H|| =',np.linalg.norm(Q.T.conj() @ A @ Q - H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度法\n",
    "\n",
    "### 最速下降法 (Steepest Descent, SD)\n",
    "\n",
    "若 $A$ 是**实对称正定**的矩阵, 求解 $Ax = b$ 可以看成求最小二乘法的解: $f(x) = x^TAx - 2x^Tb$ 的极值点. 最小二乘问题是优化问题, 可以用其它方法求得近似解. 在此仍然使用迭代法, 假定现解出一个近似解 $x$. \n",
    "\n",
    "由于负梯度方向是函数减少最快的方向, $\\nabla f = 2Ax - 2b$, 可以考虑一步迭代得到 $x' = x - \\alpha r$, 其中 $\\alpha 是参数$, $r = Ax - b$.\n",
    "\n",
    "希望 $\\Vert Ax'-b\\Vert_2$ 尽量小, 而 \n",
    "$$f(x') - f(x) = x'^TAx' - x^TAx - 2(x' - x)^Tb. $$\n",
    "\n",
    "代入 $x' = x - \\alpha r$, 其中 $r = Ax - b$, 得\n",
    "\n",
    "$$f(x') - f(x) = -2\\alpha r^TAx + \\alpha^2 r^TAr + 2\\alpha r^Tb = \\alpha^2 r^TAr - 2\\alpha r^Tr.$$\n",
    "\n",
    "因此为使得 $f(x')$ 尽量小, 应取 $\\alpha = \\frac{r^Tr}{r^TAr}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error    = 2.2386507455026984e-14\n",
      "Residual = 9.539962402197827e-14\n"
     ]
    }
   ],
   "source": [
    "def SteepestDescent(A,b,iter = -1,verbose = 0):\n",
    "    eps = (np.linalg.norm(A) * 2e-16)**2\n",
    "    if iter < 0: iter = 10 * A.shape[0] * A.shape[0]\n",
    "    x = b.copy() # 初始化\n",
    "    history = []\n",
    "    for _ in range(iter):\n",
    "        r = A @ x - b\n",
    "        normr = np.dot(r,r)\n",
    "        history.append(normr)\n",
    "        if normr <= eps: break\n",
    "        alpha = normr / np.dot(r, A @ r)\n",
    "        x -= alpha * r\n",
    "    if verbose:\n",
    "        return x , np.array(history)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "n = 50\n",
    "np.random.seed(0)\n",
    "A = np.random.randn(n*n).reshape((n,n))\n",
    "A = A.T @ A  + np.eye(n)*3\n",
    "realsol = np.random.randn(n)\n",
    "b = A @ realsol\n",
    "x = SteepestDescent(A,b)\n",
    "print('Error    =',np.linalg.norm(realsol - x))\n",
    "print('Residual =',np.linalg.norm(A @ x - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码中, 每次循环做了两次矩阵-向量乘法: $Ax$ 与 $Ar$, 这是此算法中最耗时的部分. 可以优化至一次:\n",
    "令 $p = Ar$, 则一次迭代为:\n",
    "$$\\alpha = \\frac{r^Tr}{r^Tp}$$\n",
    "$$x' = x - \\alpha r$$\n",
    "$$r' = Ax' - b = Ax - b - \\alpha Ar = r-\\alpha p$$\n",
    "$$p' = Ar' = Ar + A(r'-r) = p - \\alpha Ap$$\n",
    "\n",
    "然而, 由于舍入误差的存在, 未经校正的 $p$ 会与 $Ar$ 相差越来越大, 影响收敛速度."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最速下降法的收敛性定理: (证明见 [1] p.141)\n",
    "\n",
    "**Theorem 1** 若实对称正定矩阵 $A$ 的条件数为 $\\kappa$, 设 $x_*$ 为 $Ax = b$ 的精确解, 则用最速下降法第 $k$ 步迭代解满足:\n",
    "\n",
    "$$\\Vert x_k-x_*\\Vert_A\\leqslant \\left(\\frac{\\kappa - 1}{\\kappa + 1}\\right)^k\\Vert x_0-x_*\\Vert_A.$$\n",
    "\n",
    "其中 $\\Vert x\\Vert_A = \\sqrt{x^TAx}$ 表示 $A$-范数.\n",
    "\n",
    "容易看出, 若 $\\frac{\\kappa-1}{\\kappa+1}\\approx 1$ 则可能收敛很慢, 如以下例子尽管 $n=10$, $\\frac{\\kappa - 1}{\\kappa + 1}=0.99964$, 需要 $609835$ 步才收敛:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeff = 0.9999636644305224\n",
      "Iteration Steps = 609835\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "np.random.seed(0)\n",
    "A = np.random.randn(n*n).reshape((n,n))\n",
    "A = A.T @ A \n",
    "# 计算一下收敛因子\n",
    "eigs = np.linalg.eigvalsh(A)\n",
    "kappa = eigs[-1]/eigs[0]\n",
    "print('Coeff =',(kappa-1)/(kappa+1))\n",
    "\n",
    "realsol = np.random.randn(n)\n",
    "b = A @ realsol\n",
    "x , history = SteepestDescent(A,b,iter = 800000,verbose = True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print('Iteration Steps =',history.size)\n",
    "plt.plot(range(history.size),np.log10(history)/2.0) # 由于history是 r的范数的平方, 所以取对数后要除以2还原\n",
    "plt.title('Gradient Descent History')\n",
    "plt.xlabel('Iteration Steps')\n",
    "plt.ylabel('Logarithm of Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共轭梯度法 (Conjugate Gradient, CG)\n",
    "\n",
    "还是对于实对称正定矩阵 $A$. 在最速下降法中, 有如下定理: \n",
    "\n",
    "**Theorem 2** 最速下降法第 $k$ 步得到的近似解 $x_k$ 满足:\n",
    "$$x_k\\in x_0 + \\mathcal K(A,r_0,k).$$\n",
    "\n",
    "证: 由 $x_{k+1} = x_k - \\alpha (Ax_k - b)$, 归纳显然.\n",
    "<br>\n",
    "\n",
    "共轭梯度法则是直接希求第 $k$ 步得到的近似解是这个(平移的) Krylov 子空间的最优解:\n",
    " $$x_k = {\\rm argmin} \\{x^TAx - 2x^Tb,\\ x\\in x_0+ \\mathcal  K(A,r_0,k)\\}.$$\n",
    "\n",
    "其迭代规则如下 [3]:\n",
    "\n",
    "$$\\alpha_k = \\frac{r_k^Tr_k}{p_k^TAp_k}$$\n",
    "$$x_{k+1} = x_k + \\alpha p_k$$\n",
    "$$r_{k+1} = r_k - \\alpha Ap_k$$\n",
    "$$\\beta_{k+1} = \\frac{r_{k+1}^Tr_{k+1}}{r_k^Tr_k}$$\n",
    "$$p_{k+1} = r_{k+1} + \\beta p_k$$\n",
    "\n",
    "实际操作中, 每步只需做一次矩阵-向量乘法 ( 只计算一次 $Ap_k$ ).\n",
    "\n",
    "这个方法也可以用 Krylov 子空间理解, 见 [2] p. 634."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error    = 2.4511463427363118e-12\n",
      "Residual = 5.31290905333841e-11\n"
     ]
    }
   ],
   "source": [
    "def ConjugateGradient(A,b,iter = -1):\n",
    "    n = A.shape[0]\n",
    "    x = np.zeros(n,dtype=A.dtype)\n",
    "    r = b.copy()\n",
    "    p = r.copy()\n",
    "    Ap = A @ p\n",
    "    normr = np.dot(r,r)\n",
    "    lastnorm = 0\n",
    "    if iter < 0 : iter = n + 1\n",
    "\n",
    "    for k in range(iter):\n",
    "        alpha = normr / np.dot(p, Ap)\n",
    "        x += alpha * p\n",
    "        r -= alpha * Ap\n",
    "        lastnorm = normr\n",
    "        normr = np.dot(r,r)\n",
    "        p *= normr / lastnorm\n",
    "        p += r\n",
    "        Ap = A @ p\n",
    "        lastnorm = normr\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "n = 200\n",
    "np.random.seed(0)\n",
    "A = np.random.randn(n*n).reshape((n,n))\n",
    "A = A.T @ A  + np.eye(n)*3\n",
    "realsol = np.random.randn(n)\n",
    "b = A @ realsol\n",
    "x = ConjugateGradient(A,b)\n",
    "print('Error    =',np.linalg.norm(realsol - x))\n",
    "print('Residual =',np.linalg.norm(A @ x - b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 3** 在共轭梯度法的记号中,\n",
    "$$p_i^Tr_j=0 \\ (i<j)$$\n",
    "$$r_i^Tr_j=0 \\ (i\\neq j)$$\n",
    "$$p_i^TAp_j=0\\ (i\\neq j)$$\n",
    "$${\\rm span}\\{x_1,\\dotsc,x_{k}\\} = {\\rm span}\\{r_0,\\dotsc,r_{k-1}\\} = {\\rm span}\\{p_0,\\dotsc,p_{k-1}\\} = \\mathcal K_k$$\n",
    "\n",
    "证明见 [1] pp. 146.\n",
    "\n",
    "**Theorem 4** 假设精确解为 $Ax_* = b$, 共轭梯度法的第 $k$ 步的近似解 $x_k$ 满足:\n",
    "\n",
    " $$x_k = {\\rm argmin} \\{x^TAx - 2x^Tb,\\ x\\in x_0+ \\mathcal  K(A,r_0,k)\\}.$$\n",
    " $$x_k = {\\rm argmin} \\{\\Vert x - x_*\\Vert_A,\\ x\\in x_0+ \\mathcal  K(A,r_0,k)\\}.$$\n",
    "\n",
    "证明见 [1] pp. 148.\n",
    "\n",
    "**Theorem 5** 共轭梯度法第 $k$ 步的近似解 $x_k$ 满足:\n",
    "$$\\Vert x_k - x_*\\Vert_A\\leqslant 2\\left(\\frac{\\sqrt \\kappa - 1}{\\sqrt \\kappa +1}\\right)^k \\Vert x_0 - x_*\\Vert_A.$$\n",
    "\n",
    "证明见 [1] pp. 151. 这说明收敛速度可能与 $\\kappa$ 有关, 当 $\\kappa$ 过大收敛可能很慢."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预条件共轭梯度法 (Preconditioned Conjugate Gradient, PCG)\n",
    "\n",
    "若实对称正定矩阵 $A$ 的结构已知, 若能找到一个对称正定矩阵 $M \\approx A$, 则可以做如下操作:\n",
    "\n",
    "设其逆矩阵的 Cholesky 分解 $M^{-1} = LL^T$.\n",
    "\n",
    "$$Ax = b\\Leftrightarrow M^{-1}Ax = M^{-1}b \\Leftrightarrow LL^TAx = LL^Tb.$$\n",
    "\n",
    "即\n",
    "$$(L^TAL)(L^{-1}x) = L^{T}b.$$\n",
    "\n",
    "若 $M\\approx A^{-1}$, 则很可能有 $L^TAL \\approx I$, 即其条件数较小, 因此收敛快.\n",
    "\n",
    "经过计算化简, 若记 $\\tilde r_k = M^{-1}r_k$, 则其迭代规则如下 [4]:\n",
    "\n",
    "$$\\alpha_k = \\frac{r_k^T\\tilde r_k}{p_k^TAp_k}$$\n",
    "$$x_{k+1} = x_k + \\alpha p_k$$\n",
    "$$r_{k+1} = r_k - \\alpha Ap_k$$\n",
    "$$\\tilde r_{k+1} = M^{-1}r_{k+1}$$\n",
    "$$\\beta_{k+1} = \\frac{r_{k+1}^T\\tilde r_{k+1}}{r_k^T\\tilde r_k}$$\n",
    "$$p_{k+1} = \\tilde r_{k+1} + \\beta p_k$$\n",
    "\n",
    "可见每次循环只有唯一一处利用到了 $M$: $\\tilde r_{k+1} = M^{-1} r_k$ , 因此要取容易解方程的矩阵 $M$, 如对角阵."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. 徐树方,高立,张平文, 数值线性代数, The Peking University Press, 2nd ed., 2013.\n",
    "2. G. Golub and C. Van Loan, Matrix Computations, The Johns Hopkins University Press, Baltimore, Maryland, 4th ed., 2013.\n",
    "3. http://math.iit.edu/~fass/477577_Chapter_15.pdf\n",
    "4. http://math.iit.edu/~fass/477577_Chapter_16.pdf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1120dc956da57eca5c948a0118f4cdcd4d1b3be98c72752ed298d16085a61d24"
  },
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
